from __future__ import annotations

import os
import signal
import subprocess
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional

# Experiment Runner imports (available when running via `python experiment-runner/ <config.py>`)
from EventManager.Models.RunnerEvents import RunnerEvents
from EventManager.EventSubscriptionController import EventSubscriptionController
from ConfigValidator.Config.Models.RunTableModel import RunTableModel
from ConfigValidator.Config.Models.FactorModel import FactorModel
from ConfigValidator.Config.Models.RunnerContext import RunnerContext
from ConfigValidator.Config.Models.OperationType import OperationType
from ProgressManager.Output.OutputProcedure import OutputProcedure as output

import requests


class RunnerConfig:
    """
    Example RunnerConfig that launches the FastAPI model server from this repo
    using uvicorn, waits for it to become healthy, performs a simple interaction
    (optional warmup request) and then shuts it down. You can extend this to
    profile power/CPU by enabling profilers as shown in other examples.

    Assumptions:
    - This config is run from the repository root with:
        python experiment-runner/ experiment-runner/examples/model-server-run/RunnerConfig.py
    - The model artifacts are present under model-server/models (see setup.sh in the repo root)
    - You have a working Python that can run uvicorn and the model requirements are installed
      (use start.sh serve to create the venv and install dependencies if needed).
    """

    REPO_ROOT = Path(__file__).resolve().parents[2]
    MODEL_SERVER_DIR = REPO_ROOT / "model-server"

    # ================================ USER SPECIFIC CONFIG ================================
    name: str = "model_server_smoke"
    results_output_path: Path = Path(__file__).resolve().parent / "experiments"
    operation_type: OperationType = OperationType.AUTO
    time_between_runs_in_ms: int = 500

    # User-tunable parameters for the model server
    host: str = os.environ.get("MS_HOST", "127.0.0.1")
    port: int = int(os.environ.get("MS_PORT", "8000"))
    load_model: str = os.environ.get("LOAD_MODEL", "catboost")  # catboost | lgbm | xgboost
    log_level: str = os.environ.get("LOG_LEVEL", "info")  # info | debug

    # Internal process handle
    _proc: Optional[subprocess.Popen] = None

    def __init__(self) -> None:
        EventSubscriptionController.subscribe_to_multiple_events([
            (RunnerEvents.BEFORE_EXPERIMENT, self.before_experiment),
            (RunnerEvents.BEFORE_RUN       , self.before_run       ),
            (RunnerEvents.START_RUN        , self.start_run        ),
            (RunnerEvents.START_MEASUREMENT, self.start_measurement),
            (RunnerEvents.INTERACT         , self.interact         ),
            (RunnerEvents.STOP_MEASUREMENT , self.stop_measurement ),
            (RunnerEvents.STOP_RUN         , self.stop_run         ),
            (RunnerEvents.POPULATE_RUN_DATA, self.populate_run_data),
            (RunnerEvents.AFTER_EXPERIMENT , self.after_experiment ),
        ])
        self.run_table_model: Optional[RunTableModel] = None
        output.console_log("Model-server example config loaded")

    def create_run_table_model(self) -> RunTableModel:
        # For demonstration, we vary the model type and log level as factors
        f_model = FactorModel("model", ["catboost", "lgbm", "xgboost"])  # adjust if only some models exist
        f_log = FactorModel("log", ["info", "debug"])  # only affects server verbosity

        self.run_table_model = RunTableModel(
            factors=[f_model, f_log],
            # You can exclude combinations if some model files are missing; we filter dynamically in start_run
            exclude_combinations=[],
            repetitions=1,
            data_columns=["status_code", "healthy", "invocation_ms"],
        )
        return self.run_table_model

    # Lifecycle hooks
    def before_experiment(self) -> None:
        output.console_log("before_experiment: nothing to do")

    def before_run(self) -> None:
        output.console_log("before_run: preparing to start server")

    def start_run(self, context: RunnerContext) -> None:
        # Determine selected treatments
        treatments = getattr(context, "execute_run", {}) or {}
        model_choice = str(treatments.get("model", self.load_model))
        log_choice = str(treatments.get("log", self.log_level))

        # Resolve model file path to decide whether to skip this run
        models_dir = self.MODEL_SERVER_DIR / "models"
        mapping = {
            "catboost": "Catboost_model.pkl",
            "lgbm": "LGBM_model.pkl",
            "xgboost": "XGBoost_model.pkl",
        }
        model_file = models_dir / mapping.get(model_choice, "")
        if not model_file.exists():
            output.console_log_warning(f"Model file missing for {model_choice}: {model_file}. Skipping run.")
            setattr(context, "_skip_run", True)
            setattr(context, "_skip_data", {"healthy": False, "status_code": 0, "invocation_ms": -1})
            return

        env = os.environ.copy()
        env["LOAD_MODEL"] = model_choice
        env["LOG_LEVEL"] = log_choice.upper()

        # If you have a venv at model-server/.venv, prefer its Python and uvicorn
        venv_bin = self.MODEL_SERVER_DIR / ".venv" / ("Scripts" if sys.platform.startswith("win") else "bin")
        python_bin = venv_bin / ("python.exe" if sys.platform.startswith("win") else "python")
        uvicorn_bin = venv_bin / ("uvicorn.exe" if sys.platform.startswith("win") else "uvicorn")

        if uvicorn_bin.exists():
            cmd: List[str] = [str(uvicorn_bin), "app.main:app", "--host", self.host, "--port", str(self.port), "--log-level", log_choice]
        else:
            # Fallback to module execution via python -m uvicorn
            if python_bin.exists():
                py = str(python_bin)
            else:
                py = sys.executable
            cmd = [py, "-m", "uvicorn", "app.main:app", "--host", self.host, "--port", str(self.port), "--log-level", log_choice]

        output.console_log_bold(f"Starting model server: {' '.join(cmd)} (cwd={self.MODEL_SERVER_DIR})")
        # Important: run inside model-server directory so 'app.main' resolves and models path is correct
        self._proc = subprocess.Popen(
            cmd,
            cwd=str(self.MODEL_SERVER_DIR),
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
        )

        # Wait for health endpoint to report loaded
        base_url = f"http://{self.host}:{self.port}"
        health_url = f"{base_url}/health"
        t0 = time.time()
        timeout_s = 30
        healthy = False
        while time.time() - t0 < timeout_s:
            if self._proc.poll() is not None:
                output.console_log_error("Server process exited prematurely")
                break
            try:
                r = requests.get(health_url, timeout=2)
                if r.ok and r.json().get("loaded"):
                    healthy = True
                    break
            except Exception:
                pass
            time.sleep(0.5)
        output.console_log(f"Health status: healthy={healthy}")
        context.run_data_buffer = {"healthy": healthy, "status_code": (200 if healthy else 503)}

    def start_measurement(self, context: RunnerContext) -> None:
        # No profilers attached in this simple example
        pass

    def interact(self, context: RunnerContext) -> None:
        # Optionally perform one warmup invocation when healthy
        if getattr(context, "_skip_run", False):
            return
        data = getattr(context, "run_data_buffer", {}) or {}
        if not data.get("healthy"):
            return
        base_url = f"http://{self.host}:{self.port}"
        try:
            # Send a minimalistic payload (may fail if features are unknown); ignore errors
            t0 = time.time()
            requests.post(f"{base_url}/invocation", json={}, timeout=5)
            dt = int((time.time() - t0) * 1000)
        except Exception:
            dt = -1
        data["invocation_ms"] = dt
        context.run_data_buffer = data

    def stop_measurement(self, context: RunnerContext) -> None:
        pass

    def stop_run(self, context: RunnerContext) -> None:
        if self._proc and self._proc.poll() is None:
            output.console_log("Stopping model server")
            try:
                # Politely ask uvicorn to shutdown
                if sys.platform.startswith("win"):
                    self._proc.terminate()
                else:
                    os.kill(self._proc.pid, signal.SIGINT)
            except Exception:
                pass
            try:
                self._proc.wait(timeout=10)
            except Exception:
                try:
                    self._proc.kill()
                except Exception:
                    pass
        self._proc = None

    def populate_run_data(self, context: RunnerContext) -> Optional[Dict[str, Any]]:
        # Persist the minimal run data collected
        if getattr(context, "_skip_run", False):
            return getattr(context, "_skip_data", {"healthy": False, "status_code": 0, "invocation_ms": -1})
        return getattr(context, "run_data_buffer", None) or {"healthy": False, "status_code": 503, "invocation_ms": -1}

    def after_experiment(self) -> None:
        output.console_log("after_experiment: done")

    # ================================ DO NOT ALTER BELOW THIS LINE ================================
    experiment_path: Path = None
